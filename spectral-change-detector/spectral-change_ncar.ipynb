{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from osgeo import gdal\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import geemap.colormaps as cm\n",
    "\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Change\n",
    "\n",
    "This notebook utilizes Google Earth Engine to view trends in spectral indices over time. The temporal trends can be seasonal (one year) or over many years. Additionally, you can calculate the \"trend of the trend\" to evaluate the rate at which spectral change is occuring. \n",
    "\n",
    "You may also perform a KMeans cluster on the different spectral trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskS2clouds(image):\n",
    "    \"\"\" Mask cloud and cirrus pixels from Sentinel-2 imagery using QA60 band.\n",
    "\n",
    "        Parameters:\n",
    "        image (Image): A single Image in an ImageCollection or standalone Image\n",
    "\n",
    "        Returns:\n",
    "        Image with masked features removed and original metadata\n",
    "\n",
    "    \"\"\"\n",
    "    qa = image.select('QA60')\n",
    "\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0) \\\n",
    "        .And(qa.bitwiseAnd(cirrusBitMask).eq(0)) # performs bitwise AND operation between QA60 band and cloud bitmask\n",
    "\n",
    "    return image.updateMask(mask) \\\n",
    "        .divide(10000) \\\n",
    "        .copyProperties(image, ['system:time_start']) \n",
    "\n",
    "def maskWater(image):\n",
    "    ''' Mask out water using MODIS data.\n",
    "    \n",
    "        Define waterMask prior to running.\n",
    "\n",
    "        Returns: \n",
    "        Image with pixels where water_mask < 1. '''\n",
    "    \n",
    "    return image.updateMask(waterMask.select('water_mask').lt(1))\n",
    "\n",
    "\n",
    "def maskS2snow(image):\n",
    "    ''' Mask snow from Sentinel-2 imagery with MSK_SNWPRB (snow probability mask).\n",
    "\n",
    "        Returns: \n",
    "        Image with pixels where MSK_SNWPRB < 0.9%. '''\n",
    "    \n",
    "    mask = image.select('MSK_SNWPRB').lt(0.009)\n",
    "    \n",
    "    return image.updateMask(mask).copyProperties(image, ['system:time_start'])\n",
    "\n",
    "def maskWhite(image):\n",
    "    ''' Masks white pixels to ensure all cloudy or snowy pixels are removed.\n",
    "\n",
    "        Returns: \n",
    "        Image with pixels where grayscale is greater than or equal to 2000 are removed. '''\n",
    "\n",
    "    # convert RGB values to grayscale\n",
    "    grayscale = image.expression(\n",
    "            '(.3 * 1e4 * R) + (.59 * 1e4 * G) + (.11 * 1e4 * B)', {\n",
    "            'R': image.select('B4'),\n",
    "            'G': image.select('B3'),\n",
    "            'B': image.select('B2')\n",
    "        })\n",
    "    \n",
    "    white_mask = grayscale.lte(2000)\n",
    "\n",
    "    return image.updateMask(white_mask).copyProperties(image,['system:time_start'])\n",
    "\n",
    "def clp(image):\n",
    "    '''Clips a single Image to a region of interest'''\n",
    "    return image.clip(aoi)\n",
    "\n",
    "def addNDVI(image):\n",
    "    '''Adds S2's NDVI band to each image (in an ImageCollection)'''\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi).copyProperties(image, ['system:time_start'])\n",
    "\n",
    "def annual_images(y):\n",
    "    ''' Filters an image collection for a specific year (y) and date range (start and end month).\n",
    "        Applies the chosen analysis (mean, min, max, or median) to calculate the statistics for the images in that year.\n",
    "        \n",
    "        Requires:\n",
    "        index_collection, start_month, end_month, and analysis.\n",
    "    \n",
    "        Parameters: \n",
    "        y: a given year\n",
    "\n",
    "        Returns:\n",
    "        Statistcs over the image within the date range.\n",
    "    '''\n",
    "    # filter for given year\n",
    "    range_year = ee.Filter.calendarRange(y, y, 'year')\n",
    "    #filter for specified month range\n",
    "    range_month = ee.Filter.calendarRange(start_month, end_month, 'month')\n",
    "\n",
    "    # filter image collection by year and month and add a time band\n",
    "    filtered_dataset = (index_collection\n",
    "                        .filter(range_year)\n",
    "                        .filter(range_month)\n",
    "                        .map(lambda image: image.addBands(image.metadata('system:time_start').divide(3.154e10)))) # Needed for linear regression \n",
    "        \n",
    "    # Print out the number of images in the filtered dataset\n",
    "    num_images = filtered_dataset.size()\n",
    "    \n",
    "    # Choose the reducer based on the chosen analysis\n",
    "    if analysis == 'mean':\n",
    "        reducer = ee.Reducer.mean().combine( # calculates average value for each pixel across all images\n",
    "            reducer2=ee.Reducer.stdDev(), # calculates standard deviation\n",
    "            sharedInputs=True\n",
    "        )\n",
    "\n",
    "    elif analysis == 'min' or analysis == 'max':\n",
    "        reducer = ee.Reducer.mean().combine( # calculates minimum and maximum values\n",
    "            reducer2=ee.Reducer.minMax(),#\n",
    "            sharedInputs=True\n",
    "        )\n",
    "    elif analysis == 'median':\n",
    "        reducer = ee.Reducer.mean().combine( # calculates middle value for each pixel\n",
    "            reducer2=ee.Reducer.median(),\n",
    "            sharedInputs=True\n",
    "        )\n",
    "\n",
    "    # Use the combined reducer to get the statistics\n",
    "    stats = filtered_dataset.reduce(reducer)\n",
    "    return stats.set('year', y).set('num', num_images)\n",
    "    \n",
    "\n",
    "def intrayear(index_collection):\n",
    "    ''' Filter Image Collection within a single year. Used for seasonal (one-year) trends.\n",
    "\n",
    "        Function is used when start_year = end_year.\n",
    "\n",
    "        Requires: \n",
    "        index_collection, start_month, end_month, start_year, and end_year.\n",
    "\n",
    "        Parameters: \n",
    "        index_collection: an ImageCollection containing images with a chosen index\n",
    "\n",
    "        Returns:\n",
    "        filtered_dataset: Filtered Image Collection\n",
    "    '''\n",
    "    \n",
    "    range_year = ee.Filter.calendarRange(start_year, end_year, 'year')\n",
    "    range_month = ee.Filter.calendarRange(start_month, end_month, 'month')\n",
    "    \n",
    "    # add a time band with the year to each image \n",
    "    filtered_dataset = (index_collection\n",
    "                        .filter(range_year)\n",
    "                        .filter(range_month)\n",
    "                        .map(lambda image: image.addBands(image.metadata('system:time_start').divide(3.154e10)))) # Needed for linear regression \n",
    "    \n",
    "    num_images = filtered_dataset.size()\n",
    "\n",
    "    return filtered_dataset.set('year', start_year).set('num', num_images)\n",
    "\n",
    "\n",
    "def annual_trend(y):\n",
    "    ''' Calculate temporal trend for an index (NDVI) within a specified date range.\n",
    "        Applies a linear regression to analyze the trend of changes over time for the chosen index.\n",
    "        aka the trend of the trend!\n",
    "\n",
    "        Requires:\n",
    "        index_collection, start_month, and end_month.\n",
    "    \n",
    "        Parameters: \n",
    "        y: a given year\n",
    "\n",
    "        Returns:\n",
    "        Statistcs over the image within the date range.\n",
    "    '''\n",
    "    range_year = ee.Filter.calendarRange(y, y, 'year')\n",
    "    range_month = ee.Filter.calendarRange(start_month, end_month, 'month')\n",
    "   \n",
    "   # add a time band with the year to each image \n",
    "    filtered_dataset = (index_collection\n",
    "                        .filter(range_year)\n",
    "                        .filter(range_month)\n",
    "                        .map(lambda image: image.addBands(image.metadata('system:time_start').divide(3.154e10)))) # Needed for linear regression \n",
    "    \n",
    "    # Print out the number of images in the ImageCollection for each year\n",
    "    num_images = filtered_dataset.size()\n",
    "    \n",
    "    # Use the combined reducer to get the statistics\n",
    "    stats = filtered_dataset.reduce(reducer = ee.Reducer.linearFit())\n",
    "    return stats.set('year', y).set('num', num_images)\n",
    "\n",
    "def createTimeBand(image):   \n",
    "    '''Adds a time band to the image using metadata'''\n",
    "    return image.addBands(image.metadata('system:time_start').divide(3.154e10))\n",
    "\n",
    "def meanNDVI(image): \n",
    "    ''' Calculates the mean NDVI within a specific region.\n",
    "        \n",
    "        Requires:\n",
    "        ndvi, aoi\n",
    "\n",
    "        Returns:\n",
    "        Image with property 'ndvi_mean'. '''\n",
    "    \n",
    "    ndvi = image.select('NDVI')\n",
    "    ndvi_mean = ndvi.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=aoi,\n",
    "        scale=10\n",
    "    ).get('NDVI')\n",
    "\n",
    "    ndvi_mean = ee.Number(ndvi_mean)\n",
    "    \n",
    "    return image.set('ndvi_mean', ndvi_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build collection\n",
    "\n",
    "### Define AOI and build image collection. Choose a cell to use HYBAS watershed boundaries, coordinates, or upload a geoJSON.\n",
    "\n",
    "Option 1: Load the boundary of a wastershed with its level 10 HYBAS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYBAS_ID = 8100362560\n",
    "\n",
    "aoi = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_10\").filter(ee.Filter.eq('HYBAS_ID', HYBAS_ID))\n",
    "\n",
    "long = aoi.geometry().centroid().coordinates().get(0).getInfo()\n",
    "lat = aoi.geometry().centroid().coordinates().get(1).getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: use coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, long  = (68.5742199, -149.5305597)\n",
    "\n",
    "aoi_point = ee.Geometry.Point([long, lat])\n",
    "\n",
    "aoi = aoi_point.buffer(5000).bounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 3: upload geoJSON from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload .geoJSON HydroBASINS level 10 data\n",
    "\n",
    "HYBAS_ID = 8100362560\n",
    "geojson_path = '/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/hybas_lev10.geojson'\n",
    "\n",
    "aoi = geemap.geojson_to_ee(geojson_path).filter(ee.Filter.eq('HYBAS_ID', HYBAS_ID))\n",
    "\n",
    "long = aoi.geometry().centroid().coordinates().get(0).getInfo()\n",
    "lat = aoi.geometry().centroid().coordinates().get(1).getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "Adjust the years and months for the desired time range. \n",
    "Adjust CLOUDY_PIXEL_PERCENTAGE for desired cloudiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get water mask\n",
    "waterMask = (\n",
    "    ee.ImageCollection('MODIS/006/MOD44W') \n",
    "    .filter(ee.Filter.date('2015-01-01', '2015-01-02')) \n",
    "    .select('water_mask') \\\n",
    "    .first()\n",
    ")\n",
    "# Get Sentinel 2 harmonized images\n",
    "dataset = (\n",
    "    ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "                #  Filter by year\n",
    "                  .filter(ee.Filter.calendarRange(2019,2023,'year'))\n",
    "                #  Filter by month\n",
    "                  .filter(ee.Filter.calendarRange(6,9,'month'))\n",
    "                #  Pre-filter to get less cloudy granules.\n",
    "                  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 5))\n",
    "                  .filterBounds(aoi)\n",
    "                #   // This one's Toolik\n",
    "                # .filterBounds(ee.Geometry.Point(-149.5427, 68.6267).buffer(500))\n",
    "                #   // This one's Russian tree tracks\n",
    "                # .filterBounds(ee.Geometry.Point(133.16008, 66.82386).buffer(1000))\n",
    "                  .map(clp)\n",
    "                  .map(maskS2clouds)\n",
    "                  .map(maskS2snow)\n",
    "                  .map(maskWhite)\n",
    "                  .map(maskWater)\n",
    "                  .map(addNDVI)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center = (lat, long), zoom = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do analysis\n",
    "select your index and time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your index\n",
    "index = 'NDVI'\n",
    "# Choose 'mean', 'median', 'min', or 'max' for analysis\n",
    "analysis = 'max'  \n",
    "\n",
    "# limit beyond your ImageCollection\n",
    "start_year = 2019\n",
    "end_year = 2024\n",
    "start_month = 6\n",
    "end_month = 8\n",
    "\n",
    "# image collection with index band\n",
    "index_collection = dataset.select(index)  \n",
    "\n",
    "# Generate list of years\n",
    "years = ee.List.sequence(start_year, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip to different sections to:\n",
    "- view spectral trends on the map <br>\n",
    "- plot the index values of different regions <br>\n",
    "- perform a KMeans cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Trend\n",
    "## Choose temporal trend or trend of trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Temporal trend- change in index over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_year == end_year:\n",
    "    intrayear_collection = intrayear(index_collection)\n",
    "\n",
    "    item = intrayear_collection.getInfo()\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "    # Get linear fit to pixelwise trend of annual max NDVI\n",
    "    trend = intrayear_collection.select(['system:time_start',\n",
    "                                index\n",
    "                                ]).reduce(ee.Reducer.linearFit())\n",
    "\n",
    "else:\n",
    "\n",
    "    # Map over years to get yearly statistics\n",
    "    yearwise_ndvi = years.map(annual_images)\n",
    "\n",
    "    for item in yearwise_ndvi.getInfo():\n",
    "        print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "        yearCompCol = ee.ImageCollection.fromImages(yearwise_ndvi)\n",
    "\n",
    "        # Get linear fit to pixelwise trend of annual max NDVI\n",
    "        trend = yearCompCol.select(['system:time_start_mean',\n",
    "                                    f'{index}_{analysis}'\n",
    "                                    ]).reduce(ee.Reducer.linearFit())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Trend of the trend- change in seasonal trend over time (skip the above cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map over years to get annual trend\n",
    "yearwise_trend = years.map(annual_trend)\n",
    "\n",
    "for item in yearwise_trend.getInfo():\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_trend)\n",
    "\n",
    "trend = yearCompCol.reduce(ee.Reducer.linearFit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the min and max values of the trend, which will be used as the min and max values of the colorbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = trend.select('scale')\n",
    "\n",
    "tMin = scale.reduceRegion(\n",
    "    reducer=ee.Reducer.min(),\n",
    "    geometry=aoi,\n",
    "    scale=500,  # Adjust the scale depending on your resolution\n",
    "    maxPixels=1e9\n",
    ").getInfo()\n",
    "\n",
    "tMax = scale.reduceRegion(\n",
    "    reducer=ee.Reducer.max(),\n",
    "    geometry=aoi,\n",
    "    scale=500,  # Adjust the scale depending on your resolution\n",
    "    maxPixels=1e9\n",
    ").getInfo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set image limit to the number of images you would like to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_limit = 5\n",
    "\n",
    "# view RGB\n",
    "for image_id in intrayear(dataset).aggregate_array(\"system:index\").getInfo()[0:image_limit]:\n",
    "        image = intrayear(dataset).filterMetadata(\"system:index\", \"equals\", image_id).first()\n",
    "        \n",
    "        image_RGB = image.select('B4', 'B3', 'B2') \n",
    "        RGB_vis_params = {'min': 0.0, 'max': 0.3}\n",
    "        Map.addLayer(image_RGB, RGB_vis_params, ee.Image(image).date().format('yyyy-MM-dd').getInfo(), True)\n",
    "\n",
    "# view NDVI\n",
    "# for image_id in intrayear_collection.aggregate_array(\"system:index\").getInfo()[0:image_limit]:\n",
    "#         image = intrayear_collection.filterMetadata(\"system:index\", \"equals\", image_id).first()\n",
    "#         date_string = ee.Image(image).date().format('yyyy-MM-dd').getInfo()\n",
    "\n",
    "#         Map.addLayer(image.select('NDVI'), {}, f'{date_string}_NDVI', False)\n",
    "\n",
    "# view trend\n",
    "Map.addLayer(trend.select('scale'),\n",
    "              {'min': tMin, 'max': tMax,\n",
    "            'palette': ['red', 'white', 'blue']\n",
    "            },\n",
    " 'trend')\n",
    "\n",
    "# add colorbar for trend\n",
    "Map.add_colorbar_branca(colors=['red', 'white', 'blue'], vmin=tMin, vmax=tMax, layer_name='trend')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare mean trends of 2 AOIs\n",
    "### Skip the following cells if you already have GeoJSON files for your AOIs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell and draw a region of interest on the map. If the image isn't full coverage, toggle on the Esri Worldview basemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the image with the most coverage\n",
    "image_RGB = dataset.sort('NODATA_PIXEL_PERCENTAGE', False).first().select('B4', 'B3', 'B2')\n",
    "\n",
    "RGB_vis_params = {'min': 0.0, 'max': 0.3}\n",
    "Map.addLayer(image_RGB, RGB_vis_params, ee.Image(image_RGB).date().format('yyyy-MM-dd').getInfo(), True)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to polygon\n",
    "aoi = ee.FeatureCollection(Map.draw_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: export polygon as .geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfinished\n",
    "geemap.ee_export_vector(aoi, '8100362560_wt.geojson', json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin here if you are using already defined AOIs.\n",
    "\n",
    "upload an aoi (GeoJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_path = '/path.geojson'\n",
    "\n",
    "aoi = geemap.geojson_to_ee(geojson_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean NDVI of the area for each date and convert to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clp_collection = index_collection.map(clp)\n",
    "\n",
    "# average NDVI\n",
    "ndvi_collection = clp_collection.map(meanNDVI)\n",
    "\n",
    "# Map.addLayer(index_collection.first(), {}, \"clip\")\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = ndvi_collection.getInfo()\n",
    "data = []\n",
    "\n",
    "# add date and mean NDVI to data frame\n",
    "for img in image_list['features']:\n",
    "    properties = img['properties']\n",
    "    data.append({\n",
    "            'date': ee.Date(properties['system:time_start']).format('YYYY-MM-dd').getInfo(),\n",
    "            'ndvi_mean': properties.get('ndvi_mean')\n",
    "        })\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['date', 'ndvi_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv \n",
    "df.to_csv('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/toolik_slp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above cells with a different AOI. Once you have calculated the mean NDVI of your AOIs, you can load the saved CSVs to compare their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NDVI values for water track\n",
    "wt = pd.read_csv('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/toolik_wt.csv')\n",
    "\n",
    "# load NDVI values for intertrack region\n",
    "intertrack = pd.read_csv('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/toolik_slp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime\n",
    "wt['date'] = pd.to_datetime(wt['date'])\n",
    "intertrack['date'] = pd.to_datetime(intertrack['date'])\n",
    "\n",
    "# add ordinal date column to assist with plotting\n",
    "wt['date_ordinal'] = wt['date'].apply(lambda x: x.toordinal())\n",
    "intertrack['date_ordinal'] = intertrack['date'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt['region'] = 'track'\n",
    "intertrack['region'] = 'intertrack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "sns.set_theme(style = 'white')\n",
    "sns.lmplot(x='date_ordinal', y='ndvi_mean', data=intertrack)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean NDVI')\n",
    "plt.title('Temporal change in NDVI of inter-track region')\n",
    "\n",
    "interval = 21\n",
    "tick_positions = intertrack['date_ordinal'][::interval]\n",
    "tick_labels = intertrack['date'][::interval].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "plt.xticks(ticks=tick_positions, labels=tick_labels,)\n",
    "\n",
    "plt.gca().xaxis.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     Plot inverse vs normal greening\n",
    "run above cells to extract NDVI values for water track and intertrack regions.\n",
    "then, save data as either inverse or normal greening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse = pd.concat([wt, intertrack], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = pd.concat([wt, intertrack], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear regression of NDVI over time for EITHER inverse or normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'white')\n",
    "fig_inv = sns.lmplot(x='date_ordinal', y='ndvi_mean', data=inverse, hue = 'region')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean NDVI')\n",
    "plt.title('Temporal NDVI Trends of Inverse Greening Water Tracks and Surrounding Hillslope')\n",
    "\n",
    "interval = 85\n",
    "tick_positions = inverse['date_ordinal'][::interval]\n",
    "tick_labels = inverse['date'][::interval].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "plt.xticks(ticks=tick_positions, labels=tick_labels,)\n",
    "\n",
    "plt.gca().xaxis.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure (can't do lmplot with subplot axes)\n",
    "fig_inv.savefig('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/inv.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat the above steps for other region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dfs to for June ndvi\n",
    "normalJune = normal[normal['date'].dt.month == 6]\n",
    "inverseJune = inverse[inverse['date'].dt.month == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big fig\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Normal Greening linear regression\n",
    "normal_img = plt.imread('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/normal.png')\n",
    "axes[0, 0].imshow(normal_img)\n",
    "axes[0, 0].axis('off') \n",
    "\n",
    "# inverse greening linear regression\n",
    "inverse_img = plt.imread('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/inv.png')\n",
    "axes[0, 1].imshow(inverse_img)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# June Greeness\n",
    "sns.boxplot(x='region', y='ndvi_mean', data=normalJune, ax=axes[1, 0])\n",
    "axes[1, 0].set_xlabel('Region')\n",
    "axes[1, 0].set_ylabel('June NDVI')\n",
    "axes[1, 0].set_title('June Greenness by Region')\n",
    "\n",
    "sns.boxplot(x='region', y='ndvi_mean', data=inverseJune, ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Region')\n",
    "axes[1, 1].set_ylabel('June NDVI')\n",
    "axes[1, 1].set_title('June Greenness by Region with Inverse Greening')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an image with June Greeness, Greening Season Trend, Interannual greening trend, and Trend of Trend as bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the image with the most coverage\n",
    "\n",
    "trend_image = dataset.sort('NODATA_PIXEL_PERCENTAGE', False).first().select('B4', 'B3', 'B2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend of trend\n",
    "yearwise_trend = years.map(annual_trend)\n",
    "\n",
    "for item in yearwise_trend.getInfo():\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_trend)\n",
    "\n",
    "trend = yearCompCol.reduce(ee.Reducer.linearFit())\n",
    "\n",
    "scale = trend.select('scale')\n",
    "\n",
    "trend_image = trend_image.addBands(scale.rename('trend'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean growing season trend 2019-2023\n",
    "\n",
    "trend = yearCompCol.reduce(ee.Reducer.mean())\n",
    "\n",
    "scale = trend.select('scale_mean')\n",
    "\n",
    "trend_image = trend_image.addBands(scale.rename('season'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate change in annual max ndvi over time\n",
    "\n",
    "yearwise_ndvi = years.map(annual_images)\n",
    "\n",
    "for item in yearwise_ndvi.getInfo():\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_ndvi)\n",
    "\n",
    "trend = yearCompCol.select(['system:time_start_mean',\n",
    "                            'NDVI_max'\n",
    "                             ]).reduce(ee.Reducer.linearFit())\n",
    "\n",
    "scale = trend.select('scale')\n",
    "    \n",
    "trend_image = trend_image.addBands(scale.rename('temporal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate June Greenness 2019-2023\n",
    "\n",
    "end_month = 6\n",
    "\n",
    "yearwise_ndvi = years.map(annual_images)\n",
    "\n",
    "for item in yearwise_ndvi.getInfo():\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_ndvi)\n",
    "\n",
    "# Get linear fit to pixelwise trend of annual max NDVI\n",
    "trend = yearCompCol.select(['system:time_start_mean',\n",
    "                                    f'{index}_{analysis}'\n",
    "                                    ]).reduce(ee.Reducer.linearFit())\n",
    "    \n",
    "scale = trend.select('scale')\n",
    "    \n",
    "trend_image = trend_image.addBands(scale.rename('june'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = trend_image.select('temporal', 'season', 'june')\n",
    "\n",
    "training = img.sample(\n",
    "    region=aoi,\n",
    "    scale=10,\n",
    "    numPixels=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = ee.Clusterer.wekaKMeans(4).train(training) # integer = number of clusters\n",
    "\n",
    "kmeansresult = img.cluster(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RGB\n",
    "Map.addLayer(trend_image.select('B4', 'B3', 'B2'), {'min': 0.0, 'max': 0.3}, ee.Image(trend_image).date().format('yyyy-MM-dd').getInfo(), True)\n",
    "\n",
    "# plot clusters\n",
    "Map.addLayer(kmeansresult.select('cluster'),\n",
    "              {'min':0, 'max':4,\n",
    "               # 'palette': cm.palettes.viridis\n",
    "            },\n",
    " 'kmeans')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to df\n",
    "\n",
    "sample = kmeansresult.addBands(trend_image.select('trend', 'temporal','season','june')).sample(\n",
    "    region=aoi,\n",
    "    scale=10,\n",
    "    numPixels=5000\n",
    ").getInfo()\n",
    "\n",
    "data = []\n",
    "\n",
    "for feature in sample['features']:\n",
    "    properties = feature['properties']\n",
    "    data.append([properties['trend'], properties['temporal'], properties['season'], properties['june'], properties['cluster']])\n",
    "df = pd.DataFrame(data, columns=['trend', 'temporal', 'season', 'june', 'cluster'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(df['temporal'], df['season'], df['june'], c=df['cluster'], cmap='gray')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('temporal')\n",
    "ax.set_ylabel('season')\n",
    "ax.set_zlabel('june')\n",
    "\n",
    "# Legend\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"clusters\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "scatter = plt.scatter(df['june'], df['trend'], c=df['cluster'], cmap='gray', edgecolors='k')\n",
    "\n",
    "# Labels\n",
    "plt.xlabel('june')\n",
    "plt.ylabel('trend')\n",
    "\n",
    "# Legend\n",
    "legend1 = plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(kind='box', data=df, y='temporal', x='cluster', palette=\"gray\")\n",
    "plt.tight_layout()\n",
    "# plt.title('North Slope (8100362730)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
