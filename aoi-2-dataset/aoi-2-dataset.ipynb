{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ee\n",
    "import geemap\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "# import os\n",
    "from osgeo import gdal\n",
    "\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designate area of interest (AOI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up name and directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where you can change the ID of the watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you're doing watersheds\n",
    "HYBAS_ID = 3100083000\n",
    "aoi_name = str(HYBAS_ID)\n",
    "\n",
    "# If you're not\n",
    "# aoi_name = 'test_aoi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you want to save things locally\n",
    "aoi_path = Path('.', str(aoi_name))\n",
    "\n",
    "# If you're in the arctic group!\n",
    "# aoi_path = Path('/sciclone/data10/watersheds', str(aoi_name))\n",
    "\n",
    "Path(Path(aoi_path)).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: lat/long with area buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# latitude, longitude  = (65.052164, -166.264824) # Seward Peninsula \n",
    "\n",
    "# latitude, longitude  =  (-77.56947545454703, 161.22678556499886) # Taylor Valley\n",
    "\n",
    "latitude, longitude  = (68.62245827327547, -149.34257980791222) # WT6, Toolik\n",
    "\n",
    "aoi_point = ee.Geometry.Point([longitude, latitude])\n",
    "\n",
    "# Make your Polygon a FeatureCollection to conform to format of EE-hosted FeatureCollections\n",
    "# You can still generate ImageCollections with a Polygon, but the downloading step won't work\n",
    "aoi = ee.FeatureCollection(ee.Feature(ee.Geometry(aoi_point.buffer(5000).bounds())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or use the HydroSHEDS geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aoi = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_10\").filter(ee.Filter.eq('HYBAS_ID', HYBAS_ID))\n",
    "\n",
    "# longitude = aoi.geometry().centroid().coordinates().get(0).getInfo()\n",
    "# latitude = aoi.geometry().centroid().coordinates().get(1).getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use geemap's `geemap.shp_to_ee()` function to turn a local shapefile into an AOI as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define EE functions and get filtered ImageCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def maskS2clouds(image):\n",
    "        \"\"\"Masks clouds in S2 images\n",
    "\n",
    "    Parameters:\n",
    "    image (Image): A single Image in an ImageCollection or standalone Image\n",
    "\n",
    "    Returns:\n",
    "    Image with masked features and original metadata\n",
    "\n",
    "    \"\"\"\n",
    "        qa = image.select('QA60')\n",
    "\n",
    "        # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "        cloudBitMask = 1 << 10\n",
    "        cirrusBitMask = 1 << 11\n",
    "\n",
    "        # Both flags should be set to zero, indicating clear conditions.\n",
    "        mask = qa.bitwiseAnd(cloudBitMask).eq(0) \\\n",
    "            .And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "\n",
    "        return image.updateMask(mask) \\\n",
    "            .divide(10000) \\\n",
    "            .copyProperties(image, ['system:time_start'])\n",
    "\n",
    "def clp(image):\n",
    "    '''Clips a single Image to a region of interest'''\n",
    "    return image.clip(aoi)\n",
    "\n",
    "def mosaicByDate(imcol):\n",
    "        \"\"\"Creates a mosaicked Image for a single date if there are\n",
    "        multiple images from a single date \n",
    "\n",
    "    Parameters:\n",
    "    imcol (ImageCollection): An ImageCollection with images from one or more dates\n",
    "\n",
    "    Returns:\n",
    "    ImageCollection with images mosaicked by date\n",
    "\n",
    "        \"\"\"\n",
    "        # Get a list of unique dates in the image collection\n",
    "        imlist = imcol.toList(imcol.size())\n",
    "\n",
    "        unique_dates = imlist.map(lambda im: ee.Image(im).date().format(\"YYYY-MM-dd\")).distinct().getInfo()\n",
    "\n",
    "        # Create an empty list to store mosaic images\n",
    "        mosaic_imlist = []\n",
    "\n",
    "        # Loop through unique dates and create mosaic images\n",
    "        for date_str in unique_dates:\n",
    "            date = ee.Date.parse(\"YYYY-MM-dd\", date_str)\n",
    "            mosaic_image = imcol.filterDate(date, date.advance(1, \"day\")).mosaic()\n",
    "            mosaic_image = mosaic_image.set(\"system:time_start\", date.millis(), \"system:id\", date_str)\n",
    "            mosaic_imlist.append(mosaic_image)\n",
    "\n",
    "        return ee.ImageCollection(mosaic_imlist)\n",
    "\n",
    "def addNDVI(image):\n",
    "  '''Adds S2's NDVI band to each image (in an ImageCollection)'''\n",
    "  ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "  return image.addBands(ndvi)\n",
    "\n",
    "def addNDSI(image):\n",
    "    '''Adds S2's NDSI band to each image (in an ImageCollection)'''\n",
    "    ndsi = image.normalizedDifference(['B3', 'B11']).rename('NDSI')\n",
    "    return image.addBands(ndsi)\n",
    "\n",
    "def addElevation(image):\n",
    "  '''Adds ArcticDEM elevation to each image (in an ImageCollection)'''\n",
    "  elevation = ee.Image(\"UMN/PGC/ArcticDEM/V3/2m_mosaic\").select('elevation').clip(aoi).rename('ArcticDEM')\n",
    "  return image.addBands(elevation)\n",
    "\n",
    "def get_mean_snow_cover(image):\n",
    "        \"\"\"Adds a value for scene-averaged MODIS-dervied snow cover to an image (in an ImageCollection)\n",
    "\n",
    "    Parameters:\n",
    "    image (Image): A single Image in an ImageCollection or standalone Image\n",
    "\n",
    "    Returns:\n",
    "    Image with snow cover mean as a band\n",
    "\n",
    "        \"\"\"    \n",
    "        # Get MODIS snow cover product for day and location\n",
    "        ndsi_image = ee.ImageCollection('MODIS/061/MOD10A1').filterDate(\n",
    "            image.date(), image.date().advance(1, 'day')).first().select('NDSI_Snow_Cover').clip(aoi)\n",
    "        \n",
    "        image = image.addBands(ndsi_image)\n",
    "\n",
    "        # Get mean value across the scene \n",
    "        mean_value = image.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=aoi,\n",
    "            scale=100,  # Resolution of Landsat data in meters\n",
    "            maxPixels = 1e9\n",
    "        )\n",
    "\n",
    "        # Get the mean value for the band\n",
    "        mean_band_value = mean_value.get('NDSI_Snow_Cover')\n",
    "\n",
    "        # Set the mean value as an image property\n",
    "        return image.set(\"mean_\" + 'NDSI_Snow_Cover', mean_band_value)\n",
    "\n",
    "def calculateNoDataPercentage(image):\n",
    "        \"\"\"Add data on masked pixel percentage as a band\n",
    "        note that total_pixels needs to be calculated first\n",
    "\n",
    "    Parameters:\n",
    "    image (Image): A single Image in an ImageCollection or standalone Image\n",
    "\n",
    "    Returns:\n",
    "    Image with \"nodata_percentage band added\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Any masked no data stuff will be equal to 1\n",
    "        nodata_mask = image.select('B1').mask().eq(0)\n",
    "            \n",
    "        # Sum up the nodata 1's\n",
    "        # nodata_pixels = nodata_mask.reduceRegion(\n",
    "        #     reducer=ee.Reducer.sum(),\n",
    "        #     geometry=aoi,\n",
    "        #     scale=100,  # s2 res\n",
    "        #     maxPixels = 1e9\n",
    "        # )\n",
    "        \n",
    "        # # Calculate the percentage of NoData values\n",
    "        # percentage_nodata = nodata_pixels.getNumber('B1').divide(total_pixels.getNumber('B1')).multiply(100)\n",
    "\n",
    "        \n",
    "        # # Set the NoData percentage as an image property\n",
    "        # return image.set(\"nodata_percentage\", percentage_nodata)  \n",
    "        nodata_stats = nodata_mask.reduceRegion(\n",
    "        reducer=ee.Reducer.sum().combine(\n",
    "            reducer2=ee.Reducer.count(),\n",
    "            sharedInputs=True\n",
    "        ),\n",
    "        geometry=aoi,  # Assuming 'aoi' is defined somewhere in your script\n",
    "        scale=100,  # Adjust the scale according to your requirements\n",
    "        maxPixels=1e9\n",
    "        )\n",
    "\n",
    "        # Extract sum and count values\n",
    "        sum_nodata_pixels = nodata_stats.getNumber('B1_sum')\n",
    "        count_nodata_pixels = nodata_stats.getNumber('B1_count')\n",
    "\n",
    "        # Calculate percentage\n",
    "        nodata_percentage = sum_nodata_pixels.divide(count_nodata_pixels).multiply(100)\n",
    "\n",
    "        # Add NoData percentage as a band\n",
    "        return image.set('nodata_percentage', nodata_percentage)\n",
    "\n",
    "def get_white_pixel_percent(image):\n",
    "        \"\"\"Add data on pixel percentage that is white in grayscale as a band\n",
    "        note that total_pixels needs to be calculated first\n",
    "\n",
    "    Parameters:\n",
    "    image (Image): A single Image in an ImageCollection or standalone Image\n",
    "\n",
    "    Returns:\n",
    "    Image with \"white_percentage\" band added\n",
    "\n",
    "    \"\"\"    \n",
    "        grayscale = image.expression(\n",
    "            '(.3 * 1e4 * R) + (.59 * 1e4 * G) + (.11 * 1e4 * B)', {\n",
    "            # '(R + G + B) / 3', {\n",
    "            'R': image.select('B4'),\n",
    "            'G': image.select('B3'),\n",
    "            'B': image.select('B2')\n",
    "        })\n",
    "\n",
    "        white_mask = grayscale.gt(2000)\n",
    "        \n",
    "        # white_mask needs to = 1\n",
    "\n",
    "        # white_pixels = white_mask.reduceRegion(\n",
    "        #     reducer=ee.Reducer.sum(),\n",
    "        #     geometry=aoi,\n",
    "        #     scale=100,  # s2 res\n",
    "        #     maxPixels = 1e9\n",
    "        # )\n",
    "\n",
    "        # # # Calculate the total number of pixels within the ROI\n",
    "        # # total_pixels = image.select('B1').reduceRegion(\n",
    "        # #     reducer=ee.Reducer.count(),\n",
    "        # #     scale=10,  # s2 res\n",
    "        # #     maxPixels = 1e9\n",
    "        # # )\n",
    "\n",
    "        # # percentage_white = white_pixels.getNumber('constant').divide(total_pixels.getNumber('B1')).multiply(100)\n",
    "        \n",
    "        # total_pixels = image.getNumber('total_pixels')  # Get total_pixels from the image properties\n",
    "\n",
    "        # percentage_white = white_pixels.getNumber('constant').divide(total_pixels).multiply(100)\n",
    "        \n",
    "        # # Set the NoData percentage as an image property\n",
    "        # return image.set(\"white_percentage\", percentage_white).set(\"white_pixel_count\", white_pixels.getNumber('constant')) \n",
    "        white_pixel_stats = white_mask.reduceRegion(\n",
    "        reducer=ee.Reducer.sum().combine(\n",
    "                reducer2=ee.Reducer.count(),\n",
    "                sharedInputs=True\n",
    "            ),\n",
    "            geometry=aoi,  # Assuming 'aoi' is defined somewhere in your script\n",
    "            scale=100,  # Adjust the scale according to your requirements\n",
    "            maxPixels=1e9\n",
    "        )\n",
    "\n",
    "        # Extract sum and count values\n",
    "        sum_white_pixels = white_pixel_stats.getNumber('constant_sum')\n",
    "        count_white_pixels = white_pixel_stats.getNumber('constant_count')\n",
    "\n",
    "        # Calculate percentage\n",
    "        white_percentage = sum_white_pixels.divide(count_white_pixels).multiply(100)\n",
    "\n",
    "        return image.set(\"white_percentage\", white_percentage)\n",
    "\n",
    "def calcTotalPixels(image):\n",
    "    \"\"\"Add data on total pixels as a band\n",
    "\n",
    "    Parameters:\n",
    "    image (Image): A single Image in an ImageCollection or standalone Image\n",
    "\n",
    "    Returns:\n",
    "    Image with \"total_pixels\" band added\n",
    "\n",
    "    \"\"\"    \n",
    "    total_pixels = image.select('B1').reduceRegion(\n",
    "        reducer=ee.Reducer.count(),\n",
    "        scale=100,  \n",
    "        maxPixels = 1e9,\n",
    "        geometry=aoi\n",
    "    )\n",
    "    return image.set(\"total_pixels\", total_pixels.getNumber('B1')) \n",
    "\n",
    "def getVisibleImages(Map):\n",
    "        \"\"\"Retrieves names of layers visible on the Map \n",
    "\n",
    "    Parameters:\n",
    "    Map (Map): A geemap.Map() \n",
    "\n",
    "    Returns:\n",
    "    A list of strings corresponding to the labels on the Map layers\n",
    "    if they are dates (as needed for the original notebook)\n",
    "\n",
    "    \"\"\"    \n",
    "        map_layers = list(Map.layers)\n",
    "        visibility_status = [layer.visible for layer in map_layers]\n",
    "        visible_layers = [x.name for x, y in zip(map_layers, visibility_status) if y == True]\n",
    "        return [x for x in visible_layers if '-' in x and datetime.strptime(x, '%Y-%m-%d')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set filtering parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you notice that your ImageCollections are empty, try changing these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Good Arctic thresholds\n",
    "snow_cover_threshold = 0\n",
    "threshold_nodata_percent = 0.5\n",
    "threshold_white_percent = 2\n",
    "\n",
    "## Antarctica is much whiter\n",
    "# snow_cover_threshold = 100\n",
    "# threshold_nodata_percent = 50\n",
    "# threshold_white_percent = 100\n",
    "\n",
    "\n",
    "# Limit images added to the Map\n",
    "image_limit=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ImageCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step involves loading in Sentinel 2 data and applies your first filter for dates and cloudy percentage as well as filtering to images that intersect with the bounds of your area of interest and masking for clouds. \n",
    "\n",
    "For detecting water tracks we want to look at the growing season (months 5 to 9) but adjust based on science question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = (\n",
    "                ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                .filter(ee.Filter.calendarRange(2019,2023,'year'))\n",
    "                .filter(ee.Filter.calendarRange(5,9,'month'))\n",
    "                # Pre-filter to get less cloudy granules.\n",
    "                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "                # .filterBounds(aoi.centroid())'\n",
    "                .filterBounds(aoi)\n",
    "                .map(clp)\n",
    "                .map(maskS2clouds)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add any extra bands or data prior to filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = mosaicByDate(dataset).map(addNDVI).map(addNDSI).map(addElevation)\n",
    "\n",
    "collection_with_data = dataset.map(calcTotalPixels).map(calculateNoDataPercentage).map(get_white_pixel_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in collection: 26\n"
     ]
    }
   ],
   "source": [
    "# Basically a \"too many aggregated requests\" error can be thrown if you do TOO much at once (like three reduceRegions and filters)\n",
    "# So my strategy here is to subsume the snow filter into the white filter\n",
    "\n",
    "filtered_collection = collection_with_data.filter(ee.Filter.lte(\"nodata_percentage\", threshold_nodata_percent))\n",
    "filtered_collection = filtered_collection.filter(ee.Filter.lte(\"white_percentage\", threshold_white_percent))\n",
    "\n",
    "filtered_collection_size = len(filtered_collection.aggregate_array(\"system:index\").getInfo())\n",
    "\n",
    "print(f'Number of images in collection: {filtered_collection_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This line only instantiates a \"Map\" object from gee\n",
    "# You need to make one to add layers to it\n",
    "# but we don't display it yet \n",
    "\n",
    "# If you run this line after adding layers, \n",
    "# you will lose the layers because you made a new Map\n",
    "Map = geemap.Map(center=[latitude, longitude], zoom=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember I am limiting the image list to 5 of 26 images\n"
     ]
    }
   ],
   "source": [
    "for image_id in filtered_collection.aggregate_array(\"system:index\").getInfo()[0:image_limit]:\n",
    "    image = filtered_collection.filterMetadata(\"system:index\", \"equals\", image_id).first()\n",
    "    \n",
    "    image_RGB = image.select('B4', 'B3', 'B2') \n",
    "    # image_RGB = image.select('B4') \n",
    "    RGB_vis_params = {'min': 0.0, 'max': 0.3}\n",
    "    Map.addLayer(image_RGB, RGB_vis_params, ee.Image(image).date().format('yyyy-MM-dd').getInfo(), True)\n",
    "\n",
    "print(f'Remember I am limiting the image list to {image_limit} of {filtered_collection_size} images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9be18f22cdb4a54b93004d7de3b9f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[68.62245827327547, -149.34257980791222], controls=(WidgetControl(options=['position', 'transparentâ€¦"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you click on the wrench in the right top corner, followed by the \"Layers\" button, you can toggle through imagery that passed the filter. \n",
    "\n",
    "If you notice squares missing from the imagery, it might be a rendering/tiling issue - if you zoom in and out the map will re-tile and the problem is usually solved. The data are there, I promise. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can download any imagery you want by keeping that layer visible and running the following script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4021ea3a9abb4ba3a31589f10fe2ec5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_aoi_2019-06-01_RGB.tif: |          | 0.00/5.73M (raw) [  0.0%] in 00:00 (eta:     ?)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa51104ea2040e990afd6466d9fb911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_aoi_2019-06-01_NDVI.tif: |          | 0.00/7.64M (raw) [  0.0%] in 00:00 (eta:     ?)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There is no STAC entry for: 2019-06-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607104a0e50441ebab13596021826c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_aoi_2019-06-01_ArcticDEM.tif: |          | 0.00/191M (raw) [  0.0%] in 00:00 (eta:     ?)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_layers = getVisibleImages(Map)\n",
    "\n",
    "for date_string in date_layers:\n",
    "    print(date_string)\n",
    "\n",
    "    imageDate = ee.Date(date_string)\n",
    "\n",
    "    to_download = filtered_collection.filterDate(imageDate).first().visualize(\n",
    "        bands=['B4', 'B3', 'B2'],\n",
    "        min=0.001, max=0.3\n",
    "        )\n",
    "\n",
    "    if isinstance(aoi, ee.featurecollection.FeatureCollection):\n",
    "        geemap.ee_to_shp(((aoi)), filename=str(aoi_path.joinpath(f'{aoi_name}.shp')))\n",
    "    \n",
    "        geemap.download_ee_image(to_download, str(aoi_path.joinpath(f'{aoi_name}_{date_string}_RGB.tif')), scale=10, region=aoi.geometry(), crs='EPSG:3995')\n",
    "\n",
    "        to_download = filtered_collection.filterDate(imageDate).first().select('NDVI')\n",
    "\n",
    "        geemap.download_ee_image(to_download, str(aoi_path.joinpath(f'{aoi_name}_{date_string}_NDVI.tif')), scale=10, region=aoi.geometry(), crs='EPSG:3995')\n",
    "\n",
    "        to_download = filtered_collection.filterDate(imageDate).first().select('ArcticDEM')\n",
    "\n",
    "        geemap.download_ee_image(to_download, str(aoi_path.joinpath(f'{aoi_name}_ArcticDEM.tif')), scale=2, region=aoi.geometry(), crs='EPSG:3995')\n",
    "\n",
    "    else:\n",
    "        print(\"Your AOI is not a FeatureCollection, using backup routine.\")\n",
    "\n",
    "        geemap.ee_to_shp(ee.FeatureCollection(ee.Feature(ee.Geometry(aoi))), filename=str(aoi_path.joinpath(f'{aoi_name}.shp')))\n",
    "  \n",
    "        geemap.download_ee_image(to_download, str(aoi_path.joinpath(f'{aoi_name}_{date_string}_RGB.tif')), scale=10, region=aoi, crs='EPSG:3995')\n",
    "\n",
    "        to_download = filtered_collection.filterDate(imageDate).first().select('NDVI')\n",
    "\n",
    "        geemap.download_ee_image(to_download, str(aoi_path.joinpath(f'{aoi_name}_{date_string}_NDVI.tif')), scale=10, region=aoi, crs='EPSG:3995')\n",
    "\n",
    "        to_download = filtered_collection.filterDate(imageDate).first().select('ArcticDEM')\n",
    "\n",
    "        geemap.download_ee_image(to_download, str(aoi_path.joinpath(f'{aoi_name}_ArcticDEM.tif')), scale=2, region=aoi, crs='EPSG:3995')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform additional topographic metric calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between this step and the next, you could perform any number of additional analyses and save the results as a geotiff of any resolution (e.g. flow accumulation, curvature). As long as the file ends up in the directory you downloaded these images to, the next steps will work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming soon: a glob that also globs for dates (in case you put multiple days' images for the same AOI in the same directory.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_path = Path(aoi_path, 'aligned')\n",
    "Path(aligned_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `res_flag` sets whether you want to match the lowest resolution in your dataset (`\"max\"`) or your highest (`\"min\"`). For example, ArcticDEM is 2 m but Sentinel 2 RGB is 10 m. `'min'` would make everything 2 m (which would split Sentinel 2 pixels up), and `'max'` would make everything 10 m (which would coarsen the ArcticDEM). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your generator object\n",
    "tif_list = list(aoi_path.glob('*.tif'))\n",
    "\n",
    "ds_list = []\n",
    "\n",
    "res_flag = 'max'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script creates a folder \"`aligned`\" within the main imagery directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tif in tif_list:\n",
    "    # Changing data type for consistent nan \n",
    "    # revisit\n",
    "    src = rioxarray.open_rasterio(tif).astype('float32')\n",
    "    src.attrs['_FillValue'] = np.nan\n",
    "    ds_list.append(src)\n",
    "res_list = [src.rio.transform()[0] for src in ds_list]\n",
    "\n",
    "if res_flag == 'min':\n",
    "    # This finds dataset with minimum resolution and makes a list with everything BUT that\n",
    "    to_align = ds_list[:(res_list).index(min(res_list))] + ds_list[(res_list).index(min(res_list)) + 1:]\n",
    "    to_name = tif_list[:(res_list).index(min(res_list))] + tif_list[(res_list).index(min(res_list)) + 1:]\n",
    "\n",
    "    # This aligns each of the \"other\" datasets to the minimum-resolution dataset\n",
    "    # and **writes over** the EE-downloaded data \n",
    "    for i, src in enumerate(to_align):\n",
    "        aligned = src.rio.reproject_match(ds_list[(res_list).index(min(res_list))]).rio.to_raster(Path(aligned_path, to_name[i].name))\n",
    "\n",
    "elif res_flag == 'max':\n",
    "    # This finds dataset with maximum resolution and makes a list with everything BUT that\n",
    "    to_align = ds_list[:(res_list).index(max(res_list))] + ds_list[(res_list).index(max(res_list)) + 1:]\n",
    "    to_name = tif_list[:(res_list).index(max(res_list))] + tif_list[(res_list).index(max(res_list)) + 1:]\n",
    "\n",
    "    # This aligns each of the \"other\" datasets to the minimum-resolution dataset\n",
    "    # and **writes over** the EE-downloaded data \n",
    "    for i, src in enumerate(to_align):\n",
    "        aligned = src.rio.reproject_match(ds_list[(res_list).index(max(res_list))]).rio.to_raster(Path(aligned_path, to_name[i].name))\n",
    "\n",
    "# Add the \"template\" geotiff to the directory for making jpegs\n",
    "source = [source_name for source_name in set(tif_list).difference(to_name)][0]\n",
    "\n",
    "source_path = Path(source)\n",
    "destination_path = Path(aligned_path) / source_path.name\n",
    "# source_path.replace(destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREVIEW: export as xarray dataset\n",
    "## and then play with it further\n",
    "\n",
    "# import xarray as xr\n",
    "\n",
    "# # Create a new xarray dataset with aligned data\n",
    "# ds = xr.Dataset({\n",
    "#     'dem': dem,\n",
    "#     'red': rgb.sel(band=1),\n",
    "#     'green': rgb.sel(band=2),\n",
    "#     'blue': rgb.sel(band=3),\n",
    "#     'ndvi': ndvi\n",
    "# })\n",
    "# ds['ndvi'].rio.to_raster('output/aligned_ndvi_2.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script will make a directory \"`uint8`\" within the \"`aligned`\" directory because you need to scale every aligned geotiff to 0-255 to convert it to jpeg.\n",
    "\n",
    "Note there is probably a world in which something like `tensorflow` does not need jpegs but instead just `.npz` files...a work in progress! But for now this plugs seamlessly into `segmentation_gym`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(aligned_path)\n",
    "unit_dir = Path('./test_aoi/aligned/uint8/')\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "unit_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get a list of all GeoTIFF files in the input directory\n",
    "geotiff_files = list(input_dir.glob('*.tif'))\n",
    "\n",
    "for geotiff_file in geotiff_files:\n",
    "    input_path = str(geotiff_file)\n",
    "    print(f'Reading {input_path}')\n",
    "    # Open the input GeoTIFF file\n",
    "    src_ds = gdal.Open(input_path)\n",
    "    if src_ds is None:\n",
    "        print(f\"Failed to open {input_path}\")\n",
    "        continue\n",
    "\n",
    "    # Read the data as Float32\n",
    "    float32_data = src_ds.ReadAsArray()\n",
    "\n",
    "    # Scale and convert the data to UInt8\n",
    "    uint8_data = (float32_data - np.nanmin(float32_data)) / (np.nanmax(float32_data) - np.nanmin(float32_data))\n",
    "    uint8_data = (uint8_data * 255).astype(np.uint8)\n",
    "\n",
    "    # Create a new GeoTIFF file with UInt8 data\n",
    "    output_path = unit_dir / geotiff_file.name\n",
    "    ds = gdal.GetDriverByName('GTiff').Create(\n",
    "        str(output_path),\n",
    "        src_ds.RasterXSize,\n",
    "        src_ds.RasterYSize,\n",
    "        src_ds.RasterCount,  # Number of bands\n",
    "        gdal.GDT_Byte  # Data type: UInt8\n",
    "    )\n",
    "\n",
    "    # Write the UInt8 data to the bands\n",
    "    # For single band\n",
    "    if src_ds.RasterCount == 1:\n",
    "        ds.GetRasterBand(1).WriteArray(uint8_data)\n",
    "    else:\n",
    "        # For multiband RGB\n",
    "        for band_num in range(1, src_ds.RasterCount + 1):\n",
    "            ds.GetRasterBand(band_num).WriteArray(uint8_data[band_num - 1])\n",
    "\n",
    "\n",
    "    # Set the original spatial reference\n",
    "    ds.SetProjection(src_ds.GetProjection())\n",
    "    ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
    "\n",
    "    ds.FlushCache()\n",
    "\n",
    "    # Close the datasets\n",
    "    ds = None\n",
    "    src_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally a directory is created called \"`jpegs`\" inside \"`uint8`\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_jpeg_tiles(input_path, output_dir, tile_size):\n",
    "    \"\"\"Takes a geotiff and splits it into jpeg tiles perfect for loading into\n",
    "    Doodleverse tools or any image segmentation dataset/training scheme. In the process of creating\n",
    "    (non-georeferenced) jpeg tiles it will export a .xml file for each tile so that the jpegs,\n",
    "    or any labels created with Doodler etc. can be re-georeferenced if desired. \n",
    "\n",
    "    Parameters:\n",
    "    input_path: path for geotiff you want to tile up\n",
    "    output_dir: the directory you want to stick your jpeg tiles\n",
    "    tile_size: N x N pixels per tile\n",
    "\n",
    "    Returns:\n",
    "    Nothing, but writes files to the output_dir\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    fname = input_path.stem\n",
    "\n",
    "    output_format = 'JPEG'\n",
    "    creation_options = ['QUALITY=95']\n",
    "\n",
    "    input_path = Path(input_path)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    src_ds = gdal.Open(str(input_path))\n",
    "\n",
    "    width = src_ds.RasterXSize\n",
    "    height = src_ds.RasterYSize\n",
    "    print(f\"{fname} is {width} x {height}\")\n",
    "\n",
    "    cols = width // tile_size\n",
    "    rows = height // tile_size\n",
    "\n",
    "    for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                x_offset = col * tile_size\n",
    "                y_offset = row * tile_size\n",
    "\n",
    "                # Adjust the width and height for the last row and column\n",
    "                tile_width = min(tile_size, width - x_offset)\n",
    "                tile_height = min(tile_size, height - y_offset)\n",
    "\n",
    "                output_file = output_dir / f\"{fname}_{row}_{col}.jpeg\"\n",
    "\n",
    "                ds = gdal.Translate(\n",
    "                    str(output_file),\n",
    "                    str(input_path),\n",
    "                    srcWin=[x_offset, y_offset, tile_width, tile_height],\n",
    "                    format=output_format,\n",
    "                    width=tile_width,\n",
    "                    height=tile_height,\n",
    "                    creationOptions=creation_options\n",
    "                )\n",
    "\n",
    "                # Close the output dataset\n",
    "                ds = None\n",
    "\n",
    "    # Close the source dataset\n",
    "    src_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_list = list(unit_dir.glob('*.tif'))\n",
    "tile_size = 256\n",
    "output_directory = './test_aoi/aligned/uint8/jpegs/'\n",
    "output_directory = Path(output_directory)\n",
    "output_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for tif in tif_list:\n",
    "    input_geotiff = tif\n",
    "\n",
    "    split_into_jpeg_tiles(input_geotiff, output_directory, tile_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the structure is:\n",
    "```\n",
    "some/place/you/are/working\n",
    "                    |   |   â”œâ”€â”€ your_aoi_string\n",
    "                    |   â”‚   |       â””â”€â”€ *.tif\n",
    "                    |   |   |     â”œâ”€â”€aligned\n",
    "                    |   â”‚   |       â””â”€â”€ *.tif\n",
    "                    |   |   |   |     â”œâ”€â”€uint8\n",
    "                    |   |   â”‚   |       â””â”€â”€ *.tif\n",
    "                    |   |   |   |   |     â”œâ”€â”€jpegs\n",
    "                    |   |   |   â”‚   |       â””â”€â”€ *N_N.jpeg\n",
    "                    |   |   |   â”‚   |       â””â”€â”€ *N_N.jpeg.aux.xml\n",
    "          \n",
    "\n",
    "```\n",
    "\n",
    "where `N` is a row or column number of the original geotiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can copy the RGB jpegs into your \"`assets`\" folder for Doodler and save the other outputs as other data layers for Segmentation Gym. Future iterations will automatize this part, as well as show an example of bringing in your own labels from GIS or other shapefiles if you want to skip Doodling. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
